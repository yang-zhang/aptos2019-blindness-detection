{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.kaggle.com/tanlikesmath/intro-aptos-diabetic-retinopathy-eda-starter\n",
    "- https://medium.com/@btahir/a-quick-guide-to-using-regression-with-image-data-in-fastai-117304c0af90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRFX = 'Dev070211'\n",
    "p_o = f'../output/{PRFX}'\n",
    "\n",
    "SEED = 111\n",
    "\n",
    "dbg = True\n",
    "if dbg:\n",
    "    dbgsz = 500\n",
    "\n",
    "BS = 128\n",
    "SZ = 224\n",
    "FP16 = False\n",
    "\n",
    "import multiprocessing\n",
    "num_workers=multiprocessing.cpu_count() # 2\n",
    "num_workers=0\n",
    "\n",
    "\n",
    "from fastai.vision import *\n",
    "xtra_tfms = []\n",
    "# xtra_tfms += [rgb_randomize(channel=i, thresh=1e-4) for i in range(3)]\n",
    "\n",
    "params_tfms = dict(\n",
    "     do_flip=True,\n",
    "     flip_vert=False,\n",
    "     max_rotate=10,\n",
    "     max_warp=0,\n",
    "     max_zoom=1.1,\n",
    "     p_affine=0.5,\n",
    "     max_lighting=0.2,\n",
    "     p_lighting=0.5,\n",
    "     xtra_tfms=xtra_tfms)\n",
    "\n",
    "resize_method = ResizeMethod.CROP\n",
    "padding_mode = 'zeros'\n",
    "\n",
    "USE_TTA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai.__version__:  1.0.54\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "print('fastai.__version__: ', fastai.__version__)\n",
    "\n",
    "import random \n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def set_torch_seed(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) \n",
    "        torch.backends.cudnn.deterministic = True \n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_torch_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import pandas as pd\n",
    "\n",
    "import scipy as sp\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def quadratic_weighted_kappa(y1, y2):\n",
    "    return cohen_kappa_score(y1, y2, weights='quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3662, 1928)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2grd = []\n",
    "\n",
    "p = '../input/aptos2019-blindness-detection'\n",
    "pp = Path(p)\n",
    "train = pd.read_csv(pp/'train.csv')\n",
    "test  = pd.read_csv(pp/'test.csv')\n",
    "len_blnd = len(train)\n",
    "len_blnd_test = len(test)\n",
    "\n",
    "img2grd_blnd = [(f'{p}/train_images/{o[0]}.png',o[1])  for o in train.values]\n",
    "\n",
    "len_blnd, len_blnd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1805), (2, 999), (1, 370), (4, 295), (3, 193)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img2grd += img2grd_blnd\n",
    "display(len(img2grd))\n",
    "display(Counter(o[1] for o in img2grd).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are here!\n"
     ]
    }
   ],
   "source": [
    "if np.all([Path(o[0]).exists() for o in img2grd]): print('All files are here!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3662, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(img2grd)\n",
    "df.columns = ['fnm', 'target']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_torch_seed()\n",
    "idx_blnd_train = np.where(df.fnm.str.contains('aptos2019-blindness-detection/train_images'))[0]\n",
    "idx_val = np.random.choice(idx_blnd_train, len_blnd_test, replace=False)\n",
    "df['is_val']=False\n",
    "df.loc[idx_val, 'is_val']=True\n",
    "\n",
    "if dbg:\n",
    "    df=df.head(dbgsz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(**params_tfms)\n",
    "\n",
    "def get_data(sz, bs):\n",
    "    src = (ImageList.from_df(df=df,path='./',cols='fnm') \n",
    "            .split_from_df(col='is_val') \n",
    "            .label_from_df(cols='target',  \n",
    "                           label_cls=FloatList)\n",
    "          )\n",
    "\n",
    "    data= (src.transform(tfms,\n",
    "                         size=sz,\n",
    "                         resize_method=resize_method,\n",
    "                         padding_mode=padding_mode) #Data augmentation\n",
    "            .databunch(bs=bs,num_workers=num_workers) #DataBunch\n",
    "            .normalize(imagenet_stats) #Normalize     \n",
    "           )\n",
    "    return data\n",
    "\n",
    "bs = BS \n",
    "sz = SZ\n",
    "data = get_data(sz, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(7,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.39 ms, sys: 40.7 ms, total: 47 ms\n",
      "Wall time: 985 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
    "\n",
    "# Making pretrained weights work without needing to find the default filename\n",
    "if not os.path.exists('/tmp/.cache/torch/checkpoints/'):\n",
    "        os.makedirs('/tmp/.cache/torch/checkpoints/')\n",
    "!cp '../input/pytorch-vision-pretrained-models/resnet50-19c8e357.pth' '/tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, \n",
    "                    base_arch = models.resnet50, \n",
    "                    path=p_o)\n",
    "learn.loss = MSELossFlat\n",
    "if FP16: learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "CPU times: user 38min 42s, sys: 7min 31s, total: 46min 13s\n",
      "Wall time: 35min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn.freeze()\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 2.29E-02\n",
      "Min loss divided by 10: 1.45E-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='4', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/4 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, max_lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('mdl-frozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='6', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/6 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-81506ff92181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, max_lr=slice(1e-6,1e-3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  2 14:59:35 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   40C    P0    32W / 250W |   6289MiB / 16280MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('mdl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"sum_cpu\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/vision/tta.py\u001b[0m in \u001b[0;36m_TTA\u001b[0;34m(learn, beta, scale, ds_type, with_loss)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtta_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mavg_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"sum_cpu\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds_val, y_val = learn.TTA(ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "preds_val, y_val = learn.get_preds(ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ee3723a59db8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preds_val' is not defined"
     ]
    }
   ],
   "source": [
    "preds_val = preds_val.numpy().squeeze()\n",
    "\n",
    "y_val= y_val.numpy()\n",
    "\n",
    "np.save(f'{p_o}/preds_val.npy', preds_val)\n",
    "np.save(f'{p_o}/y_val.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/88773#latest-515044\n",
    "# We used OptimizedRounder given by hocop1. https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/76107#480970\n",
    "# put numerical value to one of bins\n",
    "def to_bins(x, borders):\n",
    "    for i in range(len(borders)):\n",
    "        if x <= borders[i]:\n",
    "            return i\n",
    "    return len(borders)\n",
    "\n",
    "class Hocop1OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _loss(self, coef, X, y, idx):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        ll = -quadratic_weighted_kappa(y, X_p)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        coef = [1.5, 2.0, 2.5, 3.0]\n",
    "        golden1 = 0.618\n",
    "        golden2 = 1 - golden1\n",
    "        ab_start = [(1, 2), (1.5, 2.5), (2, 3), (2.5, 3.5)]\n",
    "        for it1 in range(10):\n",
    "            for idx in range(4):\n",
    "                # golden section search\n",
    "                a, b = ab_start[idx]\n",
    "                # calc losses\n",
    "                coef[idx] = a\n",
    "                la = self._loss(coef, X, y, idx)\n",
    "                coef[idx] = b\n",
    "                lb = self._loss(coef, X, y, idx)\n",
    "                for it in range(20):\n",
    "                    # choose value\n",
    "                    if la > lb:\n",
    "                        a = b - (b - a) * golden1\n",
    "                        coef[idx] = a\n",
    "                        la = self._loss(coef, X, y, idx)\n",
    "                    else:\n",
    "                        b = b - (b - a) * golden2\n",
    "                        coef[idx] = b\n",
    "                        lb = self._loss(coef, X, y, idx)\n",
    "        self.coef_ = {'x': coef}\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/76107#480970\n",
    "class AbhishekOptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = quadratic_weighted_kappa(y, X_p)\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket(preds_raw, coef = [0.5, 1.5, 2.5, 3.5]):\n",
    "    preds = np.zeros(preds_raw.shape)\n",
    "    for i, pred in enumerate(preds_raw):\n",
    "        if pred < coef[0]:\n",
    "            preds[i] = 0\n",
    "        elif pred >= coef[0] and pred < coef[1]:\n",
    "            preds[i] = 1\n",
    "        elif pred >= coef[1] and pred < coef[2]:\n",
    "            preds[i] = 2\n",
    "        elif pred >= coef[2] and pred < coef[3]:\n",
    "            preds[i] = 3\n",
    "        else:\n",
    "            preds[i] = 4\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optnm2coefs = {'simple': [0.5, 1.5, 2.5, 3.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "optR = Hocop1OptimizedRounder()\n",
    "optR.fit(preds_val, y_val)\n",
    "optnm2coefs['hocop1'] = optR.coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "optR = AbhishekOptimizedRounder()\n",
    "optR.fit(preds_val, y_val)\n",
    "optnm2coefs['abhishek'] = optR.coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optnm2coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optnm2preds_val_grd = {k: bucket(preds_val, coef) for k,coef in optnm2coefs.items()}\n",
    "\n",
    "optnm2qwk = {k: quadratic_weighted_kappa(y_val, preds) for k,preds in optnm2preds_val_grd.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optnm2qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(y_val).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optnm2preds_val_grd['abhishek'].squeeze().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(optnm2preds_val_grd['abhishek'].squeeze()).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(optnm2preds_val_grd['abhishek'], y_val))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(optnm2preds_val_grd['abhishek'].squeeze()== y_val.squeeze()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(optnm2qwk, open(f'{p_o}/optnm2qwk.p', 'wb'))\n",
    "pickle.dump(optnm2coefs, open(f'{p_o}/optnm2coefs.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This goes to Kernel!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRFX = ''\n",
    "p_o = '.'\n",
    "\n",
    "SEED = 111\n",
    "\n",
    "dbg = True\n",
    "if dbg:\n",
    "    dbgsz = 500\n",
    "\n",
    "BS = 128\n",
    "SZ = 224\n",
    "FP16 = True\n",
    "\n",
    "from fastai.vision import *\n",
    "xtra_tfms = []\n",
    "# xtra_tfms += [rgb_randomize(channel=i, thresh=1e-4) for i in range(3)]\n",
    "\n",
    "params_tfms = dict(\n",
    "     do_flip=True,\n",
    "     flip_vert=False,\n",
    "     max_rotate=10,\n",
    "     max_warp=0,\n",
    "     max_zoom=1.1,\n",
    "     p_affine=0.5,\n",
    "     max_lighting=0.2,\n",
    "     p_lighting=0.5,\n",
    "     xtra_tfms=xtra_tfms)\n",
    "\n",
    "resize_method = ResizeMethod.CROP\n",
    "padding_mode = 'zeros'\n",
    "\n",
    "USE_TTA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.54'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2grd = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3662, 1928)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = '../input/aptos2019-blindness-detection'\n",
    "pp = Path(p)\n",
    "train = pd.read_csv(pp/'train.csv')\n",
    "test  = pd.read_csv(pp/'test.csv')\n",
    "len_blnd = len(train)\n",
    "len_blnd_test = len(test)\n",
    "\n",
    "img2grd_blnd = [(f'{p}/train_images/{o[0]}.png',o[1])  for o in train.values]\n",
    "\n",
    "len_blnd, len_blnd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1805), (2, 999), (1, 370), (4, 295), (3, 193)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img2grd += img2grd_blnd\n",
    "display(len(img2grd))\n",
    "display(Counter(o[1] for o in img2grd).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are here!\n"
     ]
    }
   ],
   "source": [
    "if np.all([Path(o[0]).exists() for o in img2grd]): print('All files are here!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3662, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(img2grd)\n",
    "df.columns = ['fnm', 'target']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fnm</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/aptos2019-blindness-detection/train_i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/aptos2019-blindness-detection/train_i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/aptos2019-blindness-detection/train_i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/aptos2019-blindness-detection/train_i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/aptos2019-blindness-detection/train_i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 fnm  target\n",
       "0  ../input/aptos2019-blindness-detection/train_i...       2\n",
       "1  ../input/aptos2019-blindness-detection/train_i...       4\n",
       "2  ../input/aptos2019-blindness-detection/train_i...       1\n",
       "3  ../input/aptos2019-blindness-detection/train_i...       0\n",
       "4  ../input/aptos2019-blindness-detection/train_i...       0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_torch_seed()\n",
    "idx_blnd_train = np.where(df.fnm.str.contains('aptos2019-blindness-detection/train_images'))[0]\n",
    "idx_val = np.random.choice(idx_blnd_train, len_blnd_test, replace=False)\n",
    "df['is_val']=False\n",
    "df.loc[idx_val, 'is_val']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dbg:\n",
    "    df=df.head(dbgsz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(**params_tfms)\n",
    "\n",
    "def get_data(sz, bs):\n",
    "    src = (ImageList.from_df(df=df,path='./',cols='fnm') \n",
    "            .split_from_df(col='is_val') \n",
    "            .label_from_df(cols='target',  \n",
    "                           label_cls=FloatList)\n",
    "          )\n",
    "\n",
    "    data= (src.transform(tfms,\n",
    "                         size=sz,\n",
    "                         resize_method=resize_method,\n",
    "                         padding_mode=padding_mode) #Data augmentation\n",
    "            .databunch(bs=bs,num_workers=2) #DataBunch\n",
    "            .normalize(imagenet_stats) #Normalize     \n",
    "           )\n",
    "    return data\n",
    "\n",
    "bs = BS \n",
    "sz = SZ\n",
    "data = get_data(sz, bs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.show_batch(rows=3, figsize=(7,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 36 ms, total: 36 ms\n",
      "Wall time: 736 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
    "\n",
    "# Making pretrained weights work without needing to find the default filename\n",
    "if not os.path.exists('/tmp/.cache/torch/checkpoints/'):\n",
    "        os.makedirs('/tmp/.cache/torch/checkpoints/')\n",
    "!cp '../input/pytorch-vision-pretrained-models/resnet50-19c8e357.pth' '/tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, \n",
    "                    base_arch = models.resnet50, \n",
    "                    metrics = [mse], \n",
    "                    path=p_o)\n",
    "learn.loss = MSELossFlat\n",
    "if FP16: learn = learn.to_fp16()\n",
    "learn = learn.load('mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005cfc8afb6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003f0afdcd15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006efc72b638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00836aaacf06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009245722fa4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code\n",
       "0  0005cfc8afb6\n",
       "1  003f0afdcd15\n",
       "2  006efc72b638\n",
       "3  00836aaacf06\n",
       "4  009245722fa4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.add_test(\n",
    "    ImageList.from_df(df_test,\n",
    "                      '../input/aptos2019-blindness-detection',\n",
    "                      folder='test_images',\n",
    "                      suffix='.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='8', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/8 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12' class='' max='18', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      66.67% [12/18 00:56<00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# Predictions for test set\n",
    "preds_tst, _ = learn.TTA(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Predictions for test set\n",
    "preds_tst, _ = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds_tst =  preds_tst.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket(preds_raw, coef = [0.5, 1.5, 2.5, 3.5]):\n",
    "    preds = np.zeros(preds_raw.shape)\n",
    "    for i, pred in enumerate(preds_raw):\n",
    "        if pred < coef[0]:\n",
    "            preds[i] = 0\n",
    "        elif pred >= coef[0] and pred < coef[1]:\n",
    "            preds[i] = 1\n",
    "        elif pred >= coef[1] and pred < coef[2]:\n",
    "            preds[i] = 2\n",
    "        elif pred >= coef[2] and pred < coef[3]:\n",
    "            preds[i] = 3\n",
    "        else:\n",
    "            preds[i] = 4\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optnm2qwk = pickle.load(open(f'{p_o}/optnm2qwk.p','rb'))\n",
    "optnm2coefs = pickle.load(open(f'{p_o}/optnm2coefs.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optnm2qwk, optnm2coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = optnm2coefs['abhishek']\n",
    "preds_tst_grd = bucket(preds_tst, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tst_grd.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(preds_tst_grd.squeeze()).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv(\"../input/aptos2019-blindness-detection/test.csv\")\n",
    "subm['diagnosis'] = preds_tst_grd.squeeze().astype(int)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subm.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv(f\"{p_o}/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
