{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\r\n"
     ]
    }
   ],
   "source": [
    "SEED_START = 100\n",
    "n_seeds = 40\n",
    "\n",
    "PRFX = 'Rndsd0816'\n",
    "\n",
    "p_o = f'../output/{PRFX}'\n",
    "\n",
    "# p_o = f'.'\n",
    "\n",
    "from pathlib import Path\n",
    "Path(p_o).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "!ls $p_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbg = False\n",
    "if dbg: dbgsz=1000\n",
    "\n",
    "from fastai.vision import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet-pytorch==0.3.0 from file:///tmp/working/data/git/blnd/input/efficientnetpytorch/efficientnet_pytorch-0.3.0-py3-none-any.whl in /opt/conda/lib/python3.6/site-packages (0.3.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from efficientnet-pytorch==0.3.0) (1.1.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch->efficientnet-pytorch==0.3.0) (1.16.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/efficientnetpytorch/efficientnet_pytorch-0.3.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 16 18:12:43 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   46C    P0    42W / 300W |     10MiB / 16130MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Downloading: \"http://storage.googleapis.com/public-models/efficientnet-b3-c8376fa2.pth\" to /tmp/.cache/torch/checkpoints/efficientnet-b3-c8376fa2.pth\n",
    "import os\n",
    "if not os.path.exists('/tmp/.cache/torch/checkpoints/'):\n",
    "        os.makedirs('/tmp/.cache/torch/checkpoints/')\n",
    "\n",
    "!cp ../input/efficientnetpytorch/*.pth /tmp/.cache/torch/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet-b0 size 224\n",
      "efficientnet-b1 size 240\n",
      "efficientnet-b2 size 260\n",
      "efficientnet-b3 size 300\n",
      "efficientnet-b4 size 380\n",
      "efficientnet-b5 size 456\n",
      "SZ: 456\n"
     ]
    }
   ],
   "source": [
    "BS = 16\n",
    "FP16 = True\n",
    "PERC_VAL = 0.1\n",
    "WD = 0.01\n",
    "\n",
    "\n",
    "MODEL_NAME = 'efficientnet-b5'\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "SZ = EfficientNet.get_image_size(MODEL_NAME)\n",
    "for i in range(6):\n",
    "    print(f'efficientnet-b{i} size', EfficientNet.get_image_size(f'efficientnet-b{i}'))\n",
    "print('SZ:', SZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## img proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_open_yz = True\n",
    "\n",
    "from fastai.vision import *\n",
    "import cv2\n",
    "def load_ben_color(fn)->Image:\n",
    "    image = cv2.imread(fn)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = crop_image_from_gray(image)\n",
    "    image, _ = crop_margin(image)\n",
    "    image = center_crop(image)\n",
    "    image = cv2.resize(image, (640, 480))#most common in test\n",
    "#     image = cv2.resize(image, (SZ, SZ))\n",
    "    image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX=10) , -4 ,128)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> get_transforms(do_flip:bool=True, flip_vert:bool=False, max_rotate:float=10.0, max_zoom:float=1.1, max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75, p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None) â†’ Collection[Transform]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_tfms = dict(\n",
    "    do_flip=True,\n",
    "    flip_vert=True,\n",
    "    max_rotate=360,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> By default, the library resizes the image while keeping its original ratio so that the smaller size corresponds to the given size, then takes a crop (ResizeMethod.CROP). You can choose to resize the image while keeping its original ratio so that the bigger size corresponds to the given size, then take a pad (ResizeMethod.PAD). Another way is to just squish the image to the given size (ResizeMethod.SQUISH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_tfms = dict(\n",
    "    resize_method=ResizeMethod.SQUISH,\n",
    "    padding_mode='zeros'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mod_display import *\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_torch_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) \n",
    "#         torch.backends.cudnn.deterministic = True\n",
    "#         torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def crop_margin(image, keep_less=0.83):\n",
    "    \n",
    "    output = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret,gray = cv2.threshold(gray,10,255,cv2.THRESH_BINARY)\n",
    "    contours,hierarchy = cv2.findContours(gray,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        #print('no contours!')\n",
    "        flag = 0\n",
    "        return image, flag\n",
    "    cnt = max(contours, key=cv2.contourArea)\n",
    "    ((x, y), r) = cv2.minEnclosingCircle(cnt)\n",
    "    r = r*keep_less\n",
    "    x = int(x); y = int(y); r = int(r)\n",
    "    flag = 1\n",
    "    #print(x,y,r)\n",
    "    if r > 100:\n",
    "        return output[0 + (y-r)*int(r<y):-1 + (y+r+1)*int(r<y),0 + (x-r)*int(r<x):-1 + (x+r+1)*int(r<x)], flag\n",
    "    else:\n",
    "        #print('none!')\n",
    "        flag = 0\n",
    "        return image,flag\n",
    "\n",
    "    \n",
    "def crop_image1(img,tol=7):\n",
    "    # img is image data\n",
    "    # tol  is tolerance\n",
    "        \n",
    "    mask = img>tol\n",
    "    return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    #         print(img1.shape,img2.shape,img3.shape)\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    #         print(img.shape)\n",
    "        return img\n",
    "    \n",
    "# https://stackoverflow.com/questions/16646183/crop-an-image-in-the-centre-using-pil\n",
    "def center_crop(img):        \n",
    "    \n",
    "    h0, w0 = 480, 640 #most common in test\n",
    "    ratio = h0/w0 #most common in test\n",
    "    height, width, _= img.shape\n",
    "    new_width, new_height = width, math.ceil(width*ratio)\n",
    "\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "\n",
    "    if new_width is None:\n",
    "        new_width = min(width, height)\n",
    "\n",
    "    if new_height is None:\n",
    "        new_height = min(width, height)\n",
    "\n",
    "    left = int(np.ceil((width - new_width) / 2))\n",
    "    right = width - int(np.floor((width - new_width) / 2))\n",
    "\n",
    "    top = int(np.ceil((height - new_height) / 2))\n",
    "    bottom = height - int(np.floor((height - new_height) / 2))\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        center_cropped_img = img[top:bottom, left:right]\n",
    "    else:\n",
    "        center_cropped_img = img[top:bottom, left:right, ...]\n",
    "\n",
    "    return center_cropped_img\n",
    "\n",
    "def open_yz(fn, convert_mode, after_open)->Image:\n",
    "    image = load_ben_color(fn)\n",
    "    return Image(pil2tensor(image, np.float32).div_(255))\n",
    "    \n",
    "if use_open_yz:\n",
    "    vision.data.open_image = open_yz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QWK"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import scipy as sp\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def quadratic_weighted_kappa(y1, y2):\n",
    "    return cohen_kappa_score(y1, y2, weights='quadratic')\n",
    "\n",
    "def qwk(y_pred, y):\n",
    "    return torch.tensor(\n",
    "#         quadratic_weighted_kappa(torch.round(y_pred), y),\n",
    "        quadratic_weighted_kappa(np.argmax(y_pred,1), y),\n",
    "        device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTTA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from fastai.core import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.torch_core import *\n",
    "def _tta_only(learn:Learner, ds_type:DatasetType=DatasetType.Valid, num_pred:int=5) -> Iterator[List[Tensor]]:\n",
    "    \"Computes the outputs for several augmented inputs for TTA\"\n",
    "    dl = learn.dl(ds_type)\n",
    "    ds = dl.dataset\n",
    "    old = ds.tfms\n",
    "    aug_tfms = [o for o in learn.data.train_ds.tfms if o.tfm !=zoom]\n",
    "    try:\n",
    "        pbar = master_bar(range(num_pred))\n",
    "        for i in pbar:\n",
    "            ds.tfms = aug_tfms\n",
    "            yield get_preds(learn.model, dl, pbar=pbar)[0]\n",
    "    finally: ds.tfms = old\n",
    "\n",
    "Learner.tta_only = _tta_only\n",
    "\n",
    "def _TTA(learn:Learner, beta:float=0, ds_type:DatasetType=DatasetType.Valid, num_pred:int=5, with_loss:bool=False) -> Tensors:\n",
    "    \"Applies TTA to predict on `ds_type` dataset.\"\n",
    "    preds,y = learn.get_preds(ds_type)\n",
    "    all_preds = list(learn.tta_only(ds_type=ds_type, num_pred=num_pred))\n",
    "    avg_preds = torch.stack(all_preds).mean(0)\n",
    "    if beta is None: return preds,avg_preds,y\n",
    "    else:            \n",
    "        final_preds = preds*beta + avg_preds*(1-beta)\n",
    "        if with_loss: \n",
    "            with NoneReduceOnCPU(learn.loss_func) as lf: loss = lf(final_preds, y)\n",
    "            return final_preds, y, loss\n",
    "        return final_preds, y\n",
    "\n",
    "Learner.TTA = _TTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3662, 1928)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2grd = []\n",
    "\n",
    "p = '../input/aptos2019-blindness-detection'\n",
    "pp = Path(p)\n",
    "train = pd.read_csv(pp/'train.csv')\n",
    "test  = pd.read_csv(pp/'test.csv')\n",
    "len_blnd = len(train)\n",
    "len_blnd_test = len(test)\n",
    "\n",
    "img2grd_blnd = [(f'{p}/train_images/{o[0]}.png',o[1],'blnd')  for o in train.values]\n",
    "\n",
    "len_blnd, len_blnd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1805), (2, 999), (1, 370), (4, 295), (3, 193)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.4929000546149645),\n",
       " (2, 0.272801747678864),\n",
       " (1, 0.1010376843255052),\n",
       " (4, 0.08055707263790278),\n",
       " (3, 0.052703440742763515)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img2grd += img2grd_blnd\n",
    "display(len(img2grd))\n",
    "cnt = Counter(o[1] for o in img2grd)\n",
    "t2c_trn_has = dict(cnt)\n",
    "display(cnt.most_common())\n",
    "sm = sum(cnt.values())\n",
    "display([(o[0], o[1]/sm) for o in cnt.most_common()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 27615), (2, 6291), (1, 2813), (3, 1066), (4, 1003)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "92364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 67148), (2, 14152), (1, 6575), (3, 2280), (4, 2209)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = '../input/diabetic-retinopathy-detection'\n",
    "pp = Path(p)\n",
    "train=pd.read_csv(pp/'trainLabels.csv')\n",
    "test=pd.read_csv(pp/'retinopathy_solution.csv')\n",
    "\n",
    "img2grd_diab_train=[(f'{p}/train_images/{o[0]}.jpeg', o[1], 'diab')  for o in train.values]\n",
    "img2grd_diab_test =[(f'{p}/test_images/{o[0]}.jpeg',  o[1], 'diab')  for o in test.values]\n",
    "img2grd += img2grd_diab_train\n",
    "display(len(img2grd))\n",
    "display(Counter(o[1] for o in img2grd).most_common())\n",
    "img2grd += img2grd_diab_test\n",
    "display(len(img2grd))\n",
    "display(Counter(o[1] for o in img2grd).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92777"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 67282), (2, 14288), (1, 6595), (3, 2354), (4, 2258)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "92880"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 67316), (2, 14320), (1, 6600), (3, 2373), (4, 2271)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = '../input/IDRID/B. Disease Grading'\n",
    "pp = Path(p)\n",
    "train=pd.read_csv(pp/'2. Groundtruths/a. IDRiD_Disease Grading_Training Labels.csv')\n",
    "test=pd.read_csv(pp/'2. Groundtruths/b. IDRiD_Disease Grading_Testing Labels.csv')\n",
    "\n",
    "img2grd_idrid_train=[(f'{p}/1. Original Images/a. Training Set/{o[0]}.jpg', o[1], 'idri')  for o in train.values]\n",
    "img2grd_idrid_test =[(f'{p}/1. Original Images/b. Testing Set/{o[0]}.jpg',  o[1], 'idri')  for o in test.values]\n",
    "img2grd += img2grd_idrid_train\n",
    "display(len(img2grd))\n",
    "display(Counter(o[1] for o in img2grd).most_common())\n",
    "img2grd += img2grd_idrid_test\n",
    "display(len(img2grd))\n",
    "display(Counter(o[1] for o in img2grd).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92880, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(img2grd)\n",
    "df.columns = ['fnm', 'target', 'src']\n",
    "df = df.reset_index()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54316, '../input/diabetic-retinopathy-detection/test_images/12883_left.jpeg', 0, 'diab'],\n",
       "       [46474, '../input/diabetic-retinopathy-detection/test_images/6366_left.jpeg', 0, 'diab'],\n",
       "       [45766, '../input/diabetic-retinopathy-detection/test_images/5786_left.jpeg', 4, 'diab'],\n",
       "       [37235, '../input/diabetic-retinopathy-detection/train_images/42414_right.jpeg', 0, 'diab'],\n",
       "       [91935, '../input/diabetic-retinopathy-detection/test_images/43970_right.jpeg', 0, 'diab']], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not np.all([Path(o[0]).exists() for o in img2grd]): print('Some files are missing!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '../input/aptos2019-blindness-detection'\n",
    "pp = Path(p)\n",
    "test  = pd.read_csv(pp/'test.csv')\n",
    "\n",
    "if dbg: test = test.head(dbgsz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rndsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df2use(df, seed):\n",
    "\n",
    "    df2use = df[df.src=='blnd'].copy()\n",
    "\n",
    "    def get_randint(low=200, high=1000):\n",
    "        res = np.random.randn()*300+600\n",
    "        return int(min(max(low, res), high))\n",
    "\n",
    "    set_torch_seed(seed)\n",
    "    n_t_extra = {2:get_randint(),\n",
    "                 3:get_randint(),\n",
    "                 4:get_randint(),\n",
    "                 1:get_randint()\n",
    "                }\n",
    "    print('n_t_extra:', n_t_extra)\n",
    "\n",
    "    set_torch_seed(seed)\n",
    "    for t,n in n_t_extra.items():\n",
    "        df_t_non_blnd = df[(df.target==t) & (df.src!='blnd')]\n",
    "        df2use = pd.concat([df2use, df_t_non_blnd.sample(min(n, len(df_t_non_blnd)))])\n",
    "\n",
    "    return df2use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(**params_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz=SZ, bs=BS):\n",
    "    src = (ImageList.from_df(df=df2use,path='./',cols='fnm') \n",
    "            .split_none()\n",
    "#             .split_from_df(col='is_val')\n",
    "#             .split_by_rand_pct(0.2)\n",
    "            .label_from_df(cols='target',  \n",
    "                          )\n",
    "          )\n",
    "\n",
    "    data= (src.transform(tfms, size=sz,\n",
    "                         **kwargs_tfms\n",
    "                         ) #Data augmentation\n",
    "            .databunch(bs=bs) #DataBunch\n",
    "            .normalize(imagenet_stats) #Normalize     \n",
    "           )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 100 2019-08-16 18:12:45\n",
      "n_t_extra: {2: 200, 3: 702, 4: 945, 1: 524}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1155\n",
       "0     344\n",
       "1     216\n",
       "4     107\n",
       "3     106\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 101 2019-08-16 19:26:56\n",
      "n_t_extra: {2: 1000, 3: 788, 4: 872, 1: 751}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1202\n",
       "0     337\n",
       "1     179\n",
       "3     108\n",
       "4     102\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 102 2019-08-16 21:03:12\n",
      "n_t_extra: {2: 1000, 3: 877, 4: 917, 1: 323}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1196\n",
       "0     312\n",
       "1     218\n",
       "4     109\n",
       "3      93\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 103 2019-08-16 22:32:55\n",
      "n_t_extra: {2: 225, 3: 521, 4: 715, 1: 484}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1130\n",
       "0     333\n",
       "1     209\n",
       "4     129\n",
       "3     127\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 104 2019-08-16 23:39:20\n",
      "n_t_extra: {2: 474, 3: 437, 4: 417, 1: 878}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1158\n",
       "0     313\n",
       "1     164\n",
       "4     149\n",
       "3     144\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 105 2019-08-17 00:49:14\n",
      "n_t_extra: {2: 526, 3: 415, 4: 381, 1: 617}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1199\n",
       "0     308\n",
       "1     172\n",
       "3     136\n",
       "4     113\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 106 2019-08-17 01:53:54\n",
      "n_t_extra: {2: 1000, 3: 302, 4: 735, 1: 799}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1197\n",
       "0     361\n",
       "1     164\n",
       "4     112\n",
       "3      94\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 107 2019-08-17 03:14:21\n",
      "n_t_extra: {2: 748, 3: 403, 4: 200, 1: 702}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1168\n",
       "0     350\n",
       "1     172\n",
       "3     143\n",
       "4      95\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 108 2019-08-17 04:20:20\n",
      "n_t_extra: {2: 291, 3: 666, 4: 939, 1: 943}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1197\n",
       "0     358\n",
       "1     159\n",
       "3     114\n",
       "4     100\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 109 2019-08-17 05:45:12\n",
      "n_t_extra: {2: 543, 3: 1000, 4: 317, 1: 784}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1134\n",
       "0     345\n",
       "3     174\n",
       "1     172\n",
       "4     103\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 110 2019-08-17 07:04:29\n",
      "n_t_extra: {2: 698, 3: 361, 4: 1000, 1: 200}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1209\n",
       "0     313\n",
       "3     155\n",
       "1     154\n",
       "4      97\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 111 2019-08-17 08:12:04\n",
      "n_t_extra: {2: 259, 3: 715, 4: 1000, 1: 493}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1212\n",
       "0     324\n",
       "1     194\n",
       "4     106\n",
       "3      92\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 112 2019-08-17 09:28:38\n",
      "n_t_extra: {2: 1000, 3: 205, 4: 775, 1: 745}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1182\n",
       "0     293\n",
       "1     164\n",
       "3     150\n",
       "4     139\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 113 2019-08-17 10:47:58\n",
      "n_t_extra: {2: 555, 3: 879, 4: 662, 1: 291}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1158\n",
       "0     342\n",
       "1     164\n",
       "3     153\n",
       "4     111\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 114 2019-08-17 12:00:03\n",
      "n_t_extra: {2: 593, 3: 839, 4: 401, 1: 981}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1186\n",
       "0     287\n",
       "1     227\n",
       "3     137\n",
       "4      91\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 115 2019-08-17 13:14:59\n",
      "n_t_extra: {2: 786, 3: 320, 4: 1000, 1: 200}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1229\n",
       "0     334\n",
       "1     179\n",
       "4      98\n",
       "3      88\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 116 2019-08-17 14:30:06\n",
      "n_t_extra: {2: 200, 3: 230, 4: 591, 1: 424}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1251\n",
       "0     346\n",
       "1     168\n",
       "4      88\n",
       "3      75\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 117 2019-08-17 15:24:10\n",
      "n_t_extra: {2: 200, 3: 467, 4: 722, 1: 514}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1121\n",
       "0     337\n",
       "1     238\n",
       "3     122\n",
       "4     110\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 118 2019-08-17 16:26:22\n",
      "n_t_extra: {2: 634, 3: 792, 4: 764, 1: 653}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1180\n",
       "0     330\n",
       "1     194\n",
       "3     118\n",
       "4     106\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 119 2019-08-17 17:56:57\n",
      "n_t_extra: {2: 597, 3: 961, 4: 795, 1: 371}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1242\n",
       "0     314\n",
       "1     179\n",
       "3     106\n",
       "4      87\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 120 2019-08-17 19:13:34\n",
      "n_t_extra: {2: 644, 3: 1000, 4: 471, 1: 1000}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1191\n",
       "0     356\n",
       "1     159\n",
       "3     127\n",
       "4      95\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 121 2019-08-17 20:34:58\n",
      "n_t_extra: {2: 536, 3: 514, 4: 427, 1: 467}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1221\n",
       "0     358\n",
       "1     170\n",
       "4      95\n",
       "3      84\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 122 2019-08-17 21:41:53\n",
      "n_t_extra: {2: 745, 3: 353, 4: 498, 1: 200}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1187\n",
       "0     305\n",
       "1     184\n",
       "3     153\n",
       "4      99\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 123 2019-08-17 22:56:16\n",
      "n_t_extra: {2: 274, 3: 899, 4: 684, 1: 200}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1234\n",
       "0     289\n",
       "1     179\n",
       "3     131\n",
       "4      95\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 124 2019-08-18 00:06:37\n",
      "n_t_extra: {2: 686, 3: 461, 4: 200, 1: 1000}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1223\n",
       "0     310\n",
       "1     198\n",
       "3     108\n",
       "4      89\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 125 2019-08-18 01:14:52\n",
      "n_t_extra: {2: 390, 3: 603, 4: 315, 1: 698}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1199\n",
       "0     338\n",
       "1     233\n",
       "4      87\n",
       "3      71\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 126 2019-08-18 02:18:46\n",
      "n_t_extra: {2: 401, 3: 1000, 4: 423, 1: 631}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1084\n",
       "0     319\n",
       "3     250\n",
       "1     187\n",
       "4      88\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 127 2019-08-18 03:35:12\n",
      "n_t_extra: {2: 428, 3: 608, 4: 768, 1: 405}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1237\n",
       "0     348\n",
       "1     126\n",
       "4     111\n",
       "3     106\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 128 2019-08-18 04:46:08\n",
      "n_t_extra: {2: 480, 3: 785, 4: 809, 1: 224}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1156\n",
       "0     329\n",
       "1     181\n",
       "3     141\n",
       "4     121\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 129 2019-08-18 05:55:19\n",
      "n_t_extra: {2: 200, 3: 748, 4: 371, 1: 658}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1180\n",
       "0     331\n",
       "1     188\n",
       "3     141\n",
       "4      88\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 130 2019-08-18 07:01:53\n",
      "n_t_extra: {2: 471, 3: 356, 4: 286, 1: 645}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1161\n",
       "0     325\n",
       "1     201\n",
       "3     136\n",
       "4     105\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 131 2019-08-18 08:01:29\n",
      "n_t_extra: {2: 735, 3: 645, 4: 1000, 1: 223}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1230\n",
       "0     363\n",
       "1     135\n",
       "4     107\n",
       "3      93\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 132 2019-08-18 09:15:01\n",
      "n_t_extra: {2: 435, 3: 988, 4: 748, 1: 773}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1093\n",
       "0     298\n",
       "3     232\n",
       "1     192\n",
       "4     113\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 133 2019-08-18 10:40:22\n",
      "n_t_extra: {2: 291, 3: 532, 4: 1000, 1: 474}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1163\n",
       "0     331\n",
       "1     159\n",
       "3     145\n",
       "4     130\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 134 2019-08-18 11:53:31\n",
      "n_t_extra: {2: 532, 3: 1000, 4: 864, 1: 688}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1189\n",
       "0     351\n",
       "1     156\n",
       "3     127\n",
       "4     105\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 135 2019-08-18 13:25:17\n",
      "n_t_extra: {2: 220, 3: 955, 4: 706, 1: 510}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1211\n",
       "0     335\n",
       "1     165\n",
       "3     119\n",
       "4      98\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 136 2019-08-18 14:45:49\n",
      "n_t_extra: {2: 553, 3: 553, 4: 450, 1: 476}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1155\n",
       "0     365\n",
       "1     184\n",
       "3     127\n",
       "4      97\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 137 2019-08-18 15:49:34\n",
      "n_t_extra: {2: 927, 3: 919, 4: 1000, 1: 399}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1186\n",
       "0     345\n",
       "1     176\n",
       "3     118\n",
       "4     103\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 138 2019-08-18 17:19:21\n",
      "n_t_extra: {2: 852, 3: 906, 4: 696, 1: 562}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1177\n",
       "0     326\n",
       "1     191\n",
       "3     119\n",
       "4     115\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 139 2019-08-18 18:48:11\n",
      "n_t_extra: {2: 1000, 3: 582, 4: 510, 1: 508}\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    1161\n",
       "0     275\n",
       "1     231\n",
       "3     142\n",
       "4     119\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seed in range(SEED_START, SEED_START + n_seeds):\n",
    "    print('seed:', seed, datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    df2use = get_df2use(df, seed)\n",
    "    if dbg: df2use = df2use.sample(dbgsz)\n",
    "\n",
    "    set_torch_seed(seed)\n",
    "    data = get_data()\n",
    "    data.add_test(ImageList.from_df(test,\n",
    "                                    '../input/aptos2019-blindness-detection',\n",
    "                                    folder='test_images',\n",
    "                                    suffix='.png'))\n",
    "    model = EfficientNet.from_pretrained(MODEL_NAME, num_classes=5) \n",
    "    learn = Learner(data, model, path=p_o)\n",
    "    if FP16: learn = learn.to_fp16()\n",
    "    \n",
    "    set_torch_seed(seed)\n",
    "    with progress_disabled_ctx(learn) as learn: \n",
    "        learn.fit_one_cycle(10, max_lr=1e-3)\n",
    "    learn.save(f'{PRFX}_mdl_seed_{seed}')\n",
    "    \n",
    "    with progress_disabled_ctx(learn) as learn: \n",
    "        preds_tst, _ = learn.get_preds(ds_type=DatasetType.Test)\n",
    "    preds_tst = preds_tst.numpy().squeeze()\n",
    "    preds_tst_lbls = np.argmax(preds_tst, 1)\n",
    "    display(pd.Series(preds_tst_lbls).value_counts())\n",
    "    \n",
    "    del learn, model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
